:walkthrough: Matrix to Rocket.Chat bridge ()
:user-password: openshift
:namespace: {user-username}-devspaces


:url-element: https://element-matrix.{openshift-app-host}
:url-rocketchat: https://rocketchat-rocketchat.{openshift-app-host}
:url-codeready: http://devspaces.{openshift-app-host}/
:url-devconsole: {openshift-host}/topology/ns/{namespace}


:experimental:

:btn-replace: pass:[<svg fill="#000000" width="1.5em" height="1.5em"  viewBox="0 0 912.193 912.193" xml:space="preserve"> \
  <g stroke-width="0"></g><g stroke-linecap="round" stroke-linejoin="round"></g><g> <g> <path d="M807.193,170.092v83.973c-6.033-10.458-12.529-20.674-19.512-30.606c-24.436-34.762-54.037-65.357-87.984-90.937 c-34.352-25.885-72.34-46.014-112.908-59.827c-41.957-14.286-85.891-21.529-130.577-21.529c-46.663,0-92.432,7.883-136.03,23.431 c-42.135,15.025-81.295,36.846-116.393,64.858c-34.751,27.735-64.539,60.747-88.534,98.119 c-24.444,38.072-42.191,79.621-52.748,123.492c-6.783,28.19,10.57,56.542,38.761,63.325c4.128,0.993,8.259,1.469,12.325,1.469 c23.705,0,45.21-16.167,51-40.229c15.47-64.292,52.651-122.573,104.694-164.109c26.001-20.751,54.989-36.909,86.16-48.024 c32.249-11.5,66.151-17.331,100.765-17.331c65.672,0,128.018,20.822,180.297,60.214c35.375,26.656,64.541,61.161,85.139,100.095 h-58.166c-28.994,0-52.5,23.505-52.5,52.5s23.506,52.5,52.5,52.5h196.211c28.996,0,52.5-23.505,52.5-52.5V170.092 c0-28.995-23.504-52.5-52.5-52.5C830.699,117.592,807.193,141.097,807.193,170.092z"></path> <path d="M52.5,794.602c28.995,0,52.5-23.504,52.5-52.5v-84.326c31.275,54.438,74.821,100.955,127.654,135.994 c66.246,43.936,143.417,67.186,223.196,67.254c0.044,0,0.087,0.004,0.13,0.004c0.035,0,0.071-0.002,0.106-0.002 c0.041,0,0.083,0.002,0.124,0.002c0.056,0,0.109-0.004,0.166-0.004c46.524-0.045,92.157-7.924,135.633-23.428 c42.135-15.025,81.295-36.846,116.393-64.857c34.752-27.734,64.539-60.748,88.535-98.119 c24.443-38.072,42.191-79.621,52.748-123.492c6.783-28.189-10.57-56.541-38.762-63.324s-56.541,10.57-63.324,38.76 c-15.471,64.293-52.652,122.574-104.695,164.109c-26,20.75-54.988,36.91-86.16,48.023c-32.217,11.488-66.082,17.318-100.657,17.33 c-59.154-0.023-116.346-17.229-165.398-49.762c-42.3-28.053-76.562-66.006-100.007-110.545h58.028c28.996,0,52.5-23.506,52.5-52.5 c0-28.996-23.505-52.5-52.5-52.5H52.5c-28.995,0-52.5,23.504-52.5,52.5v198.883C0,771.098,23.505,794.602,52.5,794.602z"></path> </g> </g></svg>]

// WORKS
:style-kbd: kbd { \
  color: black; \
  background-color: white; \
  border: 1px solid black; \
  box-shadow: 0px 1px black; \
  font-size: .85em; \
  line-height: .85em; \
  display: inline-block; \
  font-weight: 600; \
  letter-spacing: .05em; \
  padding: 3px 5px; \
  white-space: nowrap; \
  border-radius:5px; \
} \

:style-preview: pre {background-color: #272822; color: white; padding: 5px 15px; font-size: 15px}
:style-indent: .indent2 {padding-left: 2rem;}
:style-all: pass:a[<style>{style-kbd}{style-preview}{style-indent}</style>]


:url-docserver: https://docserver-webapp.{openshift-app-host}
//:url-docserver: http://0.0.0.0:8080

:docserver-status: pass:a[<img hidden="true" src="invalid-image.jpg" onerror=" \
        fetch('{url-docserver}/status') \
        .then(response => response.text()) \
        .then(data => this.parentElement.innerHTML = 'Status: <div style=&quot;width:15px;height:15px;border-radius:50%;background:lime;display:inline-block&quot;></div><p>&nbsp;</p>') \
        .catch(error => this.parentElement.innerHTML = 'Status: <div style=&quot;width:15px;height:15px;border-radius:50%;background:red;display:inline-block&quot;></div><p>&nbsp;</p>') \
      ">]

:freplace: pass:[function replaceTokens(templateString, values) { \
    const valueArray = values.split(',').map(val => val.trim()); \
    let result = templateString; \
    let replaceIndex = 0; \
    while (result.includes('REPLACE') && replaceIndex < valueArray.length) { \
        result = result.replace('REPLACE', valueArray[replaceIndex]); \
        replaceIndex++; \
    } \
    return result; \
}]

//:fdocserver: pass:a[function docserver(target,template,params) { \
//    {freplace} \
//    fetch('{url-docserver}/roomid?user='+params) \
//        .then(response => response.text()) \
//        .then(data => {target.firstChild.data=replaceTokens(text, data);}) \
//        .catch(error => room = 'Error fetching data: ' + error.message); \
//}]

:fdocserver: pass:a[function docserver(target,template,params) { \
    {freplace} \
    fetch('{url-docserver}'+params.trim()) \
        .then(response => response.text()) \
        .then(data => {target.firstChild.data=replaceTokens(text, data);}) \
        .catch(error => room = 'Error fetching data: ' + error.message); \
}]

:fcopy: pass:a[function copy(el) { \
  el.previousElementSibling.select(); \
  text = el.previousElementSibling.textContent; \
  console.log(text); \
  navigator.clipboard.writeText(text + '\n') \
        .then(response => console.log('Text with carriage return copied to clipboard!')) \
        .catch(err => console.error('Failed to copy: ', err)); \
}]

:copypaste: pass:a[ \
<div style="border: 1px solid #f0f0f0; border-bottom-color: #8a8d90; display: flex; align-items: flex-start;"> \
  <textarea readonly style="field-sizing: content;border: none; background-color: #f0f0f0; width: 100%; resize: none; font-size:14px; font-family: monospace;padding: 5px 15px" rows="4">function example() { \
  console.log("Hello {replace-with-previous}!"); \
  return true; \
}</textarea> \
  <button class="mytooltip" onclick="{fcopy} copy(this);" style="border: none; background-color: white; padding: 5px 15px; border-bottom: 1px solid transparent; transition: border-bottom-color 0.2s;"> \
    <svg fill="currentColor" height="1em" width="1em" viewBox="0 0 448 512" aria-hidden="true" role="img" style="vertical-align: -0.125em;"> \
      <path d="M320 448v40c0 13.255-10.745 24-24 24H24c-13.255 0-24-10.745-24-24V120c0-13.255 10.745-24 24-24h72v296c0 30.879 25.121 56 56 56h168zm0-344V0H152c-13.255 0-24 10.745-24 24v368c0 13.255 10.745 24 24 24h272c13.255 0 24-10.745 24-24V128H344c-13.2 0-24-10.8-24-24zm120.971-31.029L375.029 7.029A24 24 0 0 0 358.059 0H352v96h96v-6.059a24 24 0 0 0-7.029-16.97z"></path> \
    </svg> \
    <span class="mytooltiptext">Copy to clipboard</span> \
  </button> \
  <style> \
.mytooltip{position:relative;display:inline-block;border-bottom:1px dotted black}.mytooltip .mytooltiptext{visibility:hidden;width:120px;background-color:#555;color:#fff;text-align:center;border-radius:6px;padding:5px 0;position:absolute;z-index:1;bottom:125%;left:50%;margin-left:-60px;opacity:0;transition:opacity 0.3s}.mytooltip .mytooltiptext::after{content:"";position:absolute;top:100%;left:50%;margin-left:-5px;border-width:5px;border-style:solid;border-color:#555 transparent transparent transparent}.mytooltip:hover .mytooltiptext{visibility:visible;opacity:1} \
  </style> \
</div> \
<img hidden="true" src="invalid-image.jpg" onerror="{ \
  {fdocserver} \
  let txtarea = this.parentElement.querySelector('textarea'); \
  let div = this.closest('.paragraph'); \
  if(!div.closest('.openblock')){div = div.parentElement} \
  let source = div.nextElementSibling; \
  let pre = source.querySelector('pre'); \
  let text = pre.textContent; \
  let lineCount = text.split('\n').length; \
  let tokens = this.nextSibling; \
  console.log('tokens: [' +tokens.data.trim()+']'); \
  if(tokens.data.trim()!=''){docserver(txtarea,text,tokens.data);} else {txtarea.firstChild.data=text;} \
  source.remove(); \
  tokens.remove(); \
  this.remove(); \
}"> \
]

:snippet: pass:a[ \
<div style="border: 1px solid #f0f0f0; border-bottom-color: #8a8d90; display: flex; align-items: flex-start;"> \
</div> \
<img hidden="true" src="invalid-image.jpg" onerror="{ \
  {freplace} \
  let block = this.closest('.openblock'); \
  let div = this.closest('.paragraph'); \
  let source = div.nextElementSibling; \
  let pre = source.querySelector('pre'); \
  let text = pre.textContent; \
  let lineCount = text.split('\n').length; \
  let tokens = this.nextSibling; \
  console.log('tokens: [' +tokens.data.trim()+']'); \
  console.log('before text: [' +text+']'); \
  text = replaceTokens(text, tokens.data.trim()); \
  pre.textContent = text; \
  console.log('after text: [' +text+']'); \
  console.log(block); \
  block.parentElement.insertBefore(pre,block); \
  block.remove(); \
}"> \
]




ifdef::env-github[]
endif::[]

[id='lab3-matrix-kafka-rocketchat']
// = Lab 3 - Matrix â‡” Kafka â‡” Rocket.Chat (via streams)
= Lab 3 - Decoupled Re-Architecture

// = [[kubernetes-user]] The Kubernetes user deployment flow

Open the architecture by decoupling the chat systems using streaming capabilities with Streams for Apache Kafka.


Prerequisites: +
--
* Ensure you have previously completed the following tiles:
+
image::images/prereq.png[align="left", width=100%]

{empty} +
--

*Overview*

Lab 1 and 2 enabled _Matrix_/_Rocket.Chat_ conversations. However their connectivity was tightly coupled with dedicated data translations between both platforms. On this third lab we want to break them away to open up the architecture in order to welcome additional systems and services.

The picture below illustrates an asynchronous decoupled architecture, via a streaming platform (_Kafka_). This approach increases the number of data flows from two to four.

TIP: At first it seems unnecessary to double the number of data flows, but the benefits outweighs complexity, we gain an easily extensible architecture. In later labs you'll see new additions to the architecture.

// image::images/processing-flow.png[title="Data flow",align="center",title-align=center, width=80%]
image::images/data-flow.png[align="center", width=90%]

{empty} +

In terms of implementation effort for this lab, your main task is to split each of your current data flows (from Lab-2) in two different parts:

- The _Matrix_ to _Rocket.Chat_ process into:
. _Matrix_ to _Kafka_
. _Kafka_ to _Rocket.Chat_
+
{empty} +
- The _Rocket.Chat_ to _Matrix_ process into:
. _Rocket.Chat_ to _Kafka_
. _Kafka_ to _Matrix_

{empty} +

One fundamental architecture consideration is that if we want an easy to plugin platform where other communication systems or services need to plugin with ease, we should adopt a standard data model. It would establish a common interface for systems planning to integrate with the platform.

This implies that instead of applying platform specific data transformations (eg. _Matrix_ data model to _Rocket.Chat_ data model), we apply the following data transformations:

- System specific to standard data model (e.g. _Matrix_/_Rocket.Chat_ to _Kafka_)
- Standard data model to system specific (e.g. _Kafka_ to _Matrix_/_Rocket.Chat_)

{empty} +

The illustration below describes data exchanges via _Kafka_:

image::images/standard-data-model.png[align="center", width=90%]

{empty} +

Technical goals and milestones:

* Evolve the solution into an event-driven architecture.
* Adopt a standard interface
* Switch bindings to plug platform resources.

{empty} +


[time=2]
[id="setup"]
== Setup the Lab working folder

[type=taskResource]
.Credentials
****
* *username:* `{user-username}`
//* *password:* `{user-password}`
****
[type=taskResource]
.Red Hat OpenShift Dev Spaces
****
* link:{url-codeready}[Console, window="_blank"]
****


{empty} +

We use Lab-2 as the base for this next stage.

The following set of instructions prepare the set of files you will be working with: 


. Close tabs
+
Before you start this second lab, make sure you close in your editor all the tabs (source files) from the previous exercise.
+
image::images/crw-close-tabs.png[align="left", width=100%]
+
{blank}
+
1. Click on the file explorer's `...` button +
1. Ensure your `Open Editors` is ticked [âˆš] +
1. Click the `Close all Editors` button.
+
{empty} +

. Setup your Lab 3 folder
+
--
{copypaste}
[subs=attributes]
----
step 5
----
--
{empty} +

. Check your lab folder
+
After executing the commands above, have a look in your editor's tree view to confirm it looks healthy. It should be similar to:
+
IMAGE PENDING UPDATE
+
image::images/lab-setup.png[align="left", width=30%]
+
{empty} +

[type=verification]
Do you see the same folder structure and files?

[type=verificationSuccess]
You're ready to continue.

[type=verificationFail]
Make sure the syntax of the commands are compatible with with your environment and try again.


{empty} +


[time=5]
[id="matrix-rocketchat-to-kafka"]
== Matrix/Rocket.Chat to Kafka

[type=taskResource]
.Credentials
****
* *username:* `{user-username}`
//* *password:* `{user-password}`
****
[type=taskResource]
.Red Hat OpenShift Dev Spaces
****
* link:{url-codeready}[Console, window="_blank"]
****
[type=taskResource]
.Red Hat OpenShift Developer Console
****
* link:{url-devconsole}[Topology View, window="_blank"]
****
[type=taskResource]
.Matrix
****
* link:{url-element}[Matrix Web Client, window="_blank"]
****
[type=taskResource]
.Rocket.Chat
****
* link:{url-rocketchat}[Rocket.Chat Web Client, window="_blank"]
****

The two data flows we have created in previous labs are almost identical in terms of processing steps, those are:

. Receive events
. Filter events
. Transform events
. Push events

{empty} +

For the processes from _Matrix_/_Rocket.Chat_ to _Kafka_, the steps remain the same, we just need to switch to the standard data model (step 3) and target _Kafka_ instead (step 4).

{empty} +

=== Process overview

The diagram below applies to the data flows (2 of them) from _Matrix_/_Rocket.Chat_ respectively to _Kafka_:

image::images/new/processing-flow-chat2kafka.jpg[align="center", width=90%]
//image::images/processing-flow-chat2kafka.png[align="center", width=90%]

{empty} +

There are 4 processing steps in use:

====
* *1 source _Kamelet_* +
Consumes events from _Matrix/Rocket.Chat_.

* *2 mid-flow steps* +
One filters messages to prevent death loops. +
One transforms _Matrix/Rocket.Chat_ events to the standard data model.

* *1 producer* +
Produces events to _Kafka_.
====

{empty} +

=== Matrix to Kafka

The picture below shows the original _Matrix to Rocket.Chat_ flow you defined earlier:

image::images/new/flow-m2r.jpg[align="left", width=60%]

{blank}

The changes you need to apply on the flow above are minimal:

1. Redefine the data mapping using the common interface
1. Send the event to Kafka (instead of _Rocket.Chat_)

{blank}

To simplify the work you need to do, we've prepared the flow so that you just need to fill the blanks. The picture below illustrates the two focus areas where you need to work on:

image::images/new/flow-m2k-todo.jpg[align="left", width=70%]

{blank}

To open the Camel route definition (picture above), find in your directory tree the following resource:

* `m2k.camel.yaml`
+
Click to open it in _Kaoto_. 
+
{empty} +

Then, follow the instructions below to complete its definition:

{empty} +

. *Define the data transformation*
+
In the new data transformation, the source system remains the same (_Matrix_). However, because the event to push to _Kafka_ will target various systems, we need to use a common schema shared with all other _Camel_ flows.
+
{empty} +
+
A. Include in your Camel route a Kaoto data transformation step
+
--
From Kaoto: 

. Click the `+` button inside the `To do: Mapping` step
. Find and select the _Kaoto DataMapper_
. Click to open the configuration panel
. Click the `ðŸ”§Configure` button
--
+
{empty} +

A. Attach schemas
+
--
From the DataMapper editor: 

. Define the source:
.. On `Parameters` click the `+` to add new parameter
.. Enter `matrix` and click the checkmark button kbd:[âˆš]
.. Click first the Attach schema button, then the blue button, and pick `matrix-in.json`.
+
{blank}
+
. Define the target
.. Find the target Body and click on "Attach schema", then the blue button, and pick `common.json`
+
{empty} +
--

A. Define the data mappings rules
+
Copy and Paste the values below to define the given field entries:
+
... `string[@key = timestamp]`: 
+
--
{copypaste}
----
$matrix-x/fn:map/fn:string[@key='sent']
----
--
+
{blank}
+
... `string[@key = source]`: 
+
--
{copypaste}
----
"matrix"
----
--
+
{blank}
+
... `string[@key = user]`: 
+
--
{copypaste}
----
$matrix-x/fn:map/fn:map[@key='fromUser']/fn:string[@key='displayName']
----
--
+
{blank}
+
... `string[@key = text]`:
+
--
{copypaste}
----
$matrix-x/fn:map/fn:string[@key='text']
----
--
+
{empty} +

. *Define Kafka as the target system*
+
The last step of the flow is where you need to define Kafka as the target system where events will be pushed.
+
NOTE: Your _OpenShift_ namespace already contains an _AMQ Streams_ cluster (_Kafka_) ready for you to use. 
+

1. Click the `+` button inside the `To do: Kafka` step
1. Find and select the _Kafka_ component.
1. Select the `All` configuration tab
1. Configure the following 2 properties:
+
`Topic`:
+
--
{copypaste}
----
myroom
----
--
+
`Brokers`:
+
--
{copypaste}
----
my-cluster-kafka-bootstrap:9092
----
--
+
{empty} +

And that's all it takes for this first data flow between _Matrix_ and _Kafka_.

{empty} +



=== Rocket.Chat to Kafka

Very similar changes apply for the _Rocket.Chat_ -> _Kafka_ flow.

Find in your directory tree the following resource:

* `r2k.camel.yaml`
+
Click to open it in _Kaoto_. 
+
{empty} +

Then, follow the instructions below to complete its definition:

{empty} +

. *Define the data transformation*
+
The source system remains the same (_Rocket.Chat_). In similar fashion we also need to use a common schema shared with all other _Camel_ flows.
+
{empty} +

A. Include in your _Camel_ route a _Kaoto_ data transformation step
+
--
From Kaoto: 

. Click the `+` button in the transition
. Find and select the _Kaoto DataMapper_
. Click to open the configuration panel
. Click the `ðŸ”§Configure` button
--
+
{empty} +

A. Attach schemas
+
--
From the DataMapper editor: 

. Define the source:
.. On `Parameters` click the `+` to add new parameter
.. Enter `rocketchat` and click the checkmark button kbd:[âˆš]
.. Click first the Attach schema button, then the blue button, and pick `rocketchat-in.json`.
+
{blank}
+
. Define the target
.. Find the target Body and click on "Attach schema", then the blue button, and pick `common.json`
+
{empty} +
--

A. Define the data mappings rules
+
Copy and Paste the values below to define the given field entries:
+
... `string[@key = timestamp]`: 
+
--
{copypaste}
----
$rocketchat-x/fn:map/fn:string[@key='timestamp']
----
--
+
{blank}
+
... `string[@key = source]`: 
+
--
{copypaste}
----
"rocketchat"
----
--
+
{blank}
+
... `string[@key = user]`: 
+
--
{copypaste}
----
$rocketchat-x/fn:map/fn:string[@key='user_name']
----
--
+
{blank}
+
... `string[@key = text]`:
+
--
{copypaste}
----
$rocketchat-x/fn:map/fn:string[@key='text']
----
--
+
{empty} +

. *Define Kafka as the target system*
+
The last step of the flow is where you need to define Kafka as the target system where events will be pushed.
+
NOTE: Your _OpenShift_ namespace already contains an _AMQ Streams_ cluster (_Kafka_) ready for you to use. 
+

1. Click the `+` button inside the `To do: Kafka` step
1. Find and select the _Kafka_ component.
1. Select the `All` configuration tab
1. Configure the following 2 properties:
+
`Topic`:
+
--
{copypaste}
----
myroom
----
--
+
`Brokers`:
+
--
{copypaste}
----
my-cluster-kafka-bootstrap:9092
----
--
+
{empty} +

Very straightforward, nothing else to be done here. 

{empty} +



[time=5]
[id="kafka-to-matrix-rocketchat"]
== Kafka to Rocket.Chat/Matrix
{style-all}

[type=taskResource]
.Credentials
****
* *username:* `{user-username}`
//* *password:* `{user-password}`
****
[type=taskResource]
.Red Hat OpenShift Dev Spaces
****
* link:{url-codeready}[Console, window="_blank"]
****
[type=taskResource]
.Red Hat OpenShift Developer Console
****
* link:{url-devconsole}[Topology View, window="_blank"]
****
[type=taskResource]
.Matrix
****
* link:{url-element}[Matrix Web Client, window="_blank"]
****
[type=taskResource]
.Rocket.Chat
****
* link:{url-rocketchat}[Rocket.Chat Web Client, window="_blank"]
****

The processing steps still remain essentially the same:

. Receive events
. Filter events
. Transform events
. Push events

{empty} +

The main differences are that we are consuming events from _Kafka_ (step 1) and that we have to translate events (step 3) from the standard data model to the target specific model (e.g. _Matrix_, _Rocket.Chat_, other)

{empty} +

=== Process overview

The diagram below applies to the data flows (2 of them) from _Kafka_ to Matrix/Rocket.Chat respectively:

image::images/new/processing-flow-kafka2chat.jpg[align="center", width=90%]
//image::images/processing-flow-kafka2chat.png[align="center", width=90%]

{empty} +

There are 4 processing steps in use:

====
* *1 consumer* +
Consumes events from _Kafka_.

* *2 mid-flow steps* +
One filters messages to prevent death loops. +
One transforms events from the standard data model to _Matrix/Rocket.Chat_.

* *1 sink _Kamelet_* +
Produces events to _Matrix/Rocket.Chat_.
====

{empty} +



=== Kafka to Rocket.Chat

Like we did earlier, it's handy to use one of the previous flows as a base to construct the new _Kafka to Rocket.Chat_ proces as some of the steps are identical. The picture below shows the original _Matrix to Rocket.Chat_ flow you originally constructed:

image::images/new/flow-m2r.jpg[align="left", width=60%]

{blank}

Again, the changes you need to apply on the flow above are minimal:

1. Replace _Matrix_ as the source by a _Kafka_ consumer.
1. Redefine the filter to prevent *Rocket.Chat to Rocket.Chat* loopback events.
1. Redefine the data mapping to use the common interface as the source schema.

{blank}

To simplify the work you need to do, we've prepared the flow so that you just need to fill the blanks. The picture below illustrates the focus areas where you need to work on:

image::images/new/flow-k2r-todo.jpg[align="left", width=70%]

{blank}

Find in your directory tree the following resource:

* `k2r.camel.yaml`
+
Click to open it in _Kaoto_. 
+
{empty} +

Then, follow the instructions below to complete its definition:

{empty} +

. *Define Kafka as the source system*
+
The first step of the flow is where you need to define Kafka as the source system from where events will arrive.
+
NOTE: Your _OpenShift_ namespace already contains an _AMQ Streams_ cluster (_Kafka_) ready for you to use. 
+

1. Hover the `To do: Kafka` step and click the floating {btn-replace} button.
1. Find and select the _Kafka_ component.
1. Select the `All` configuration tab
1. Configure the following 2 properties:
+
`Topic`:
+
--
{copypaste}
----
myroom
----
--
+
`Brokers`:
+
--
{copypaste}
----
my-cluster-kafka-bootstrap:9092
----
--
+
{empty} +

. *Define the filter*
+
Filters you've previously defined are intended to block loopback events, in other words, if we push an event to _Matrix_ or _Rocket.Chat_, we don't want the same message to come back.
+
However, by decoupling the architecture using _Kafka_, we introduce another event duplication threat you need to keep under control. The problem that arises is that we're about to define flows using _Kafka_ consumers that will route any incoming event, no matter where they really originate from, and push it to a defined target. In other words, we're potentially creating flows where the source and target system is the same, for example:
+
  * _Matrix -> Matrix_
  * _Rocket.Chat -> Rochet.Chat_
  * _X -> X_
+
{blank}
+
The filter you need to define will prevent that.
+
1. Click the bar pass:[<code style="background-color: #B0380C; color: white;">&nbsp;To do: Filter&nbsp;</code>]
+
You should the `JQ` expression language is selected by default.
+
1. copy and paste the following expression:
+
--
{copypaste}
----
.source | test("rocketchat")
----
--
+
NOTE: The expression above picks the `source` JSON field from the Kafka event and checks if it originates in the Rocket.Chat system.
+
NOTE: Flows pushing events to _Kafka_ populate the field `source` to indicate where the event originates. 
+
{empty} +

. *Define the data transformation*
+
In the new data transformation, the source data complies with the common schema (from _Kafka_) while the target system needs to map data going to _Rocket.Chat_.
+
.. Include in your Camel route a Kaoto data transformation step
+
--
From Kaoto: 

. Click the `+` button inside the `To do: Mapping` box
. Find and select the _Kaoto DataMapper_
. Click to open the configuration panel
. Click the `ðŸ”§Configure` button
--
+
{empty} +

.. Attach schemas
+
--
From the DataMapper editor: 

. Define the source:
.. On `Parameters` click the `+` to add new parameter
.. Enter `common` and click the checkmark button kbd:[âˆš]
.. Click first the Attach schema button, then the blue button, and pick `common.json`.
+
{blank}
+
. Define the target
.. Find the target Body and click on "Attach schema", then the blue button, and pick `rocketchat-out.json`
+
{empty} +
--

.. Define the data mappings rules
+
Copy and Paste the values below to define the given field entries:
+
... `string[@key = channel]`: 
+
--
{copypaste}/roomid/{user-username}
----
"REPLACE"
----
--
+
{blank}
+
... `string[@key = text]`:
+
--
{copypaste}
----
concat("*",$common-x/fn:map/fn:string[@key='user'], "@", $common-x/fn:map/fn:string[@key='source'],"*", $common-x/fn:map/fn:string[@key='text'])
----
--
+
{empty} +

And youâ€™re done with the Kafka â†’ Rocket.Chat changes.

{empty} +


=== Kafka to Matrix

//Like we did earlier, it's handy to use one of the previous flows as a base to construct the new _Kafka to Matrix_ proces as many of the steps are the same. The picture below shows the original _Rocket.Chat to Matrix_ flow you defined earlier:

//image::images/new/flow-m2r.jpg[align="left", width=60%]

//{blank}

Similarly, the changes you need to apply on this flow are minimal:

1. Define a _Kafka_ consumer (instead of _Rocket.Chat_)
1. Redefine the filter to prevent *Rocket.Chat to Rocket.Chat* loopback events.
1. Redefine the data mapping to use the common interface as the source schema.

{blank}

image::images/new/flow-k2m-todo.jpg[align="left", width=70%]

{blank}

Find in your directory tree the following resource:

* `k2m.camel.yaml`
+
Click to open it in _Kaoto_. 
+
{empty} +

Then, follow the instructions below to complete its definition:

{empty} +

. *Define Kafka as the source system*
+
The first step of the flow is where you need to define _Kafka_ as the source system from where events will arrive.
+
NOTE: Your _OpenShift_ namespace already contains an _AMQ Streams_ cluster (_Kafka_) ready for you to use. 
+

1. Hover the `To do: Kafka` step and click the floating {btn-replace} button.
1. Find and select the _Kafka_ component.
1. Select the `All` configuration tab
1. Configure the following 2 properties:
+
`Topic`:
+
--
{copypaste}
----
myroom
----
--
+
`Brokers`:
+
--
{copypaste}
----
my-cluster-kafka-bootstrap:9092
----
--
+
{empty} +

. *Define the filter*
+
As previously explained, you need the define a filter to prevent events flowing from _Matrix to Matrix_.
+
1. Click the bar pass:[<code style="background-color: #B0380C; color: white;">&nbsp;To do: Filter&nbsp;</code>]
+
You should see the `JQ` expression language selected by default.
+
1. copy and paste the following expression:
+
--
{copypaste}
----
.source | test("matrix")
----
--
+
NOTE: The expression above picks the `source` JSON field from the _Kafka_ event and checks if it originates in the _Matrix_ system.
+
NOTE: Flows pushing events to _Kafka_ populate the field `source` to indicate where the event originates. 
+
{empty} +

. *Define the data transformation*
+
In the new data transformation, the source data complies with the common schema (from _Kafka_) while the target system needs to map data going to _Matrix_.
+
.. Include in your Camel route a Kaoto data transformation step
+
--
From Kaoto: 

. Click the `+` button inside the `To do: Mapping` box
. Find and select the _Kaoto DataMapper_
. Click to open the configuration panel
. Click the `ðŸ”§Configure` button
--
+
{empty} +

.. Attach schemas
+
--
From the DataMapper editor: 

. Define the source:
.. On `Parameters` click the `+` to add new parameter
.. Enter `common` and click the checkmark button kbd:[âˆš]
.. Click first the Attach schema button, then the blue button, and pick `common.json`.
+
{blank}
+
. Define the target
.. Find the target Body and click on "Attach schema", then the blue button, and pick `matrix-out.json`
+
{empty} +
--

.. Define the data mappings rules
+
Copy and Paste the values below to define the given field entries:
+
... `string[@key = text]`:
+
--
{copypaste}
----
concat("<b>",$common-x/fn:map/fn:string[@key='user'], "@", $common-x/fn:map/fn:string[@key='source'],"</b>", $common-x/fn:map/fn:string[@key='text'])
----
--
+
{empty} +

Again, very simple updates, nothing else required for the _Kafka â†’ Matrix_ process.

{empty} +


[time=8]
[id="deploy-test"]
== Deploy and test

[type=taskResource]
.Credentials
****
* *username:* `{user-username}`
//* *password:* `{user-password}`
****
[type=taskResource]
.Red Hat OpenShift Dev Spaces
****
* link:{url-codeready}[Console, window="_blank"]
****
[type=taskResource]
.Red Hat OpenShift Developer Console
****
* link:{url-devconsole}[Topology View, window="_blank"]
****
[type=taskResource]
.Matrix
****
* link:{url-element}[Matrix Web Client, window="_blank"]
****
[type=taskResource]
.Rocket.Chat
****
* link:{url-rocketchat}[Rocket.Chat Web Client, window="_blank"]
****

{empty} +

THIS CHAPTER IS YET TO BE UPDATED
IGNORE THE CONTENT BELOW. DEPLOY AS IN PREVIOUS CHAPTERS.

We've covered a lot of ground. It would be normal to make mistakes. Hopefully the helper guide kept those to a minimum and, once deployed, you can see your integrations working in healthy state and delivering the expected outcome.

. Select your _OpenShift_ project
+
For those resuming work from a previous day, ensure the _working_ project in _OpenShift_ is selected by executing the following command:
+
[source,bash,subs="attributes+"]
----
oc project {namespace}
----
+
{empty} +

. Push the configuration to _OpenShift_
+
Recreate the _Secret_ and _ConfigMap_ to include both JSLTs. +
Run the following `oc` command:
+
[source, subs=]
----
oc create secret generic stage3 --from-file=stage3.properties
oc create cm stage3-transform --from-file=maps
<br>
----
{empty} +

. Create the _Kafka_ topic
+ 
Run the following command:
+
[source, subs=]
----
mkdir kafka
touch kafka/room_x.yaml
<br>
----
+
{empty} +
+
Edit your `room_x.yaml` file under the `kafka` directory. Add the following definition
+
```yaml
kind: KafkaTopic
apiVersion: kafka.strimzi.io/v1beta2
metadata:
  name: roomx
  labels:
    strimzi.io/cluster: my-cluster
```
+
[IMPORTANT]
====
Keep the name `roomx` for your _KafkaTopic_, do not change its value, it simplifies the copy/paste actions all along the lab exercises.
====
+
[NOTE]
====
The YAML source above defines a new _Kafka_ topic with name `roomx`. This is the topic all _Camel_ producers and consumers will use.
====
+
{empty} +
+
Push the definition to _OpenShift_ with the following command:
+
```bash
oc apply -f kafka/room_x.yaml
```
{empty} +

. Deploy the YAML definition containing your new _Kamelet Binding_
.. Run the following `oc` command to deploy the integration:
+
[source, subs=]
----
oc apply -f flows/m2k.yaml
oc apply -f flows/k2r.yaml
oc apply -f flows/r2k.yaml
oc apply -f flows/k2m.yaml<br>
----
+
NOTE: Be patient, this action will take some time to complete as the operator needs to download all related dependencies, build the applications and create the images before the integrations can be deployed.

.. Wait for readyness
+
Check the deployment of all pods and their logs to ensure all is in healthy state.
+
You can run the following command to check their state:
+
```bash
oc get klb
```
+
{empty} +
+
When the pods are ready, the command should return:
+
----
NAME   PHASE   REPLICAS
m2k    Ready   1
k2m    Ready   1
k2r    Ready   1
r2k    Ready   1
----
+
{empty} +
+
Looking from your console's topology view, you should see something similar to:
+
image::images/topology-view.png[align="left", width=80%]
+
{empty} +

. Send messages to test the system.
+
.. Go to you _Matrix_'s room and send a message, for example `Hello from Matrix`.

.. Then go to you _Rocket.Chat_'s room and send a message, for example `Hello from Rocket.Chat`.
+
If all goes well you should see something similar to the picture below:
+
image::images/stage3-msg-chat-test.png[align="left", width=90%]
+
{empty} +

+
{empty} +

[type=verification]
Did you see the message going from _Matrix_ to _Rocket.Chat_?

[type=verificationSuccess]
Very good !

[type=verificationFail]
Inspect in the pod logs to troubleshoot.


[type=verification]
Did you see the message going from _Rocket.Chat_ to _Matrix_?

[type=verificationSuccess]
Very good !

[type=verificationFail]
Inspect in the pod logs to troubleshoot.



// Bravo! You've completed Stage 3 !!
